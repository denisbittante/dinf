\documentclass[main.tex]{subfiles}
\begin{document}

%% Korrigiert bis hier

\chapter{Grundlagen}

\textit{Welche Frameworks in dieser Arbeit mittels welcher Methoden und Metriken analysiert werden.}


% Welches Ziel wird mit dem Einsatz einer Engine verfolgt? 

% Welche Hauptkriterien müssen dabei untersucht werden? Warum? 

\section{Performance} 

Ian Molyneaux definiert eine performante Anwendung wie folgt:\newline
\noindent 
\say{Eine gut funktionierende Anwendung ist eine, die es dem Endbenutzer ermöglicht, eine bestimmte Aufgabe ohne übermässige Verzögerung oder Irritation auszuführen.}\cite{molyneaux2014art}

Die Schlussfolgerung davon ist, dass jeder Performance verschieden empfinden kann, aber auch, dass für jede Aufgabe das geeignetste Mittel gewählt wird, das zu keiner oder nur geringer Verzögerung führt. Eine Verzögerung kann situativ verschieden empfunden werden.

Performance ist dennoch nur ein Qualitätsmerkmal von vielen, das gemessen werden kann. Als nicht funktionale Anforderung werden neben Performanz- auch Speicherplatzanforderungen oder Benutzbarkeitsanforderungen genannt \cite[S. 120]{sommerville_2012}. Jede dieser Anforderungen kann mit der geeigneten Methodik erhoben werden. Es können als Beispiel Lasttest und Performence-Messungen auf ein bestehendes System, falls ein solches existiert, durchgeführt werden, um zu erkennen, ob eine Applikation viel oder wenig Speicher verbraucht und somit der Spericherplatzanforderung gerecht wird. Auch die Benutzbarkeit kann mittels Interaktionstests zwischen dem User und der Applikation evaluiert werden. Dies kann zeigen, ob der User auf Anhieb zurechtkommt oder das Navigationskonzept überdacht werden soll. Um die Performanzanforderungen zu analysieren, können Prototypen gebaut werden, die mittels Performancemessungen auf verschiedene Metriken hin analysiert werden. Diese Vorgehensweise wurde für diese Arbeit gewählt.

Die Performance kann mittels verschiedener Metriken ausgedrückt werden. Folgende Metriken sind für diese Arbeit relevant:

\subsection{Metriken Performance-Messungen}

\textbf{Latenzzeit (clientseitig):} Ist die Zeit ab dem Senden der Abfrage, bis sie den Zielort erreicht hat und wieder zurück beim Client ist. Sie beinhaltet die Latenzzeit des Servers und des Netzwerkes. 
\newline
\noindent
\textbf{Reaktionszeit (Response Time):} Die Antwort-Zeit ist die Zeit, die benötigt wird von der Abfrage, bis alle Antworten am System empfangen werden. Das beinhaltet die Latenzzeit des Netzwerks, des Servers und eine allfällige Latenzzeit des Quellsystems.
\newline
\noindent
\textbf{Durchsatz (Throughput):} Der Durchsatz ist die Anzahl der zu verarbeitenden Abfragen oder Bytes, die in einer definierten Zeiteinheit erledigt wurden. Es werden meist viele Stichproben gemacht, um den Verlauf protokollieren zu können. Der gesamte Durchsatz wird demzufolge so berechnet:
\begin{equation}
\textbf{Durchsatz} = \frac{\textit{anz. Abfragen}}{\textit{Gesamtzeit}}
\end{equation}
\newline
\noindent
\textbf{Verfügbarkeit (Availability):} Die Verfügbarkeit ist so lange gewährleistet, bis der User des Service die Antwort bekommt. Sobald die Antworten des Servers zu stark verzögert oder korrupt sind, ist der Service nicht mehr verfügbar. 




% Vorgehensweise klären und Begrifflichkeiten erörtern

% https://www.safaribooksonline.com/library/view/the-art-of/9781491900536/ch01.html#Chapter1

\subsection{Metriken - Ressourcen}
Damit die clientseitigen Performance-Messungen nachvollziehbar werden, wurde entschieden, auf der Service-Seite einige Performance-Indikatoren zu protokollieren. Diese sollen dann mit der guten oder schlechten Performance in Zusammenhang gebracht werden. Dabei sind diese Metriken für diese Arbeit gewählt worden.
\newline
\noindent
\textbf{Memory RSS:} Das RSS steht für 'resident set size', was die Grösse der Prozesse bezeichnet, die im Hauptspeicher gehalten werden. Diese Messung wird in MB ausgedrückt und wird jede Minute evaluiert. Das RSS wird über alle Dynos hinweg ausgegeben.
\newline
\noindent
\textbf{Memory SWAP:} Der SWAP wird dann eingesetzt, wenn die Prozesse keinen verfügbaren Speicherplatz im RSS finden. Die Prozesse werden somit auf der Festplatte sistiert. Dabei sind die Einstellungen des unterliegenden Systems ausschlaggebend, wenn dies passiert.
\newline
\noindent
\textbf{Web-Server - CPU (\gls{dyno} Last) } Das ist die Anzahl der Prozesse, die auf eine Ausführung warten und sich im Status ’Ready’ befinden. Dabei werden die Stichproben über eine und fünf Minuten aufgezeichnet.
\subsection{Plattform as a Service}

Die Performance-Messungen auf einer \acrshort{paas} auszuführen, bringt verschiedene Vorteile, wie z.B. die Möglichkeit, eine relativ grosse Infrastruktur für eine kurze Zeit günstig zu mieten. Ebenfalls kann diese relativ schnell an die Bedürfnisse angepasst werden, also z.B die Anzahl Instanzen dynamisch anzupassen und somit auf die Bedürfnisse eines Anwendungsfalls reagieren zu können. Ebenfalls kann von den voreingestellten Konfigurationen profitiert werden, da diese für die meisten Fälle bereits optimal definiert wurden. Während eines Performancetests ist es auch nötig, die Ressourcen zu protokollieren, was auf einer \acrshort{paas} dank dem Einsatz von Ad-Ons leicht zu erreichen ist. 
Doch kann eine \acrshort{paas} auch Nachteile mit sich bringen. Beispielsweise kann diese nicht immer ganz zuverlässig sein, ein Server kann vielleicht nicht wie gewohnt gestartet werden oder bricht abrupt ab. Dies stellt meist keine weitere Probleme, da diese Instanzen leicht wieder gestartet oder gelöscht werden können.\cite[Kap.~3]{molyneaux2014art} 


Heroku, die gewählte PaaS, bietet eine Möglichkeit. 
In diesem Fall wurde ein sogenannter Dyno Typ ’Standard-2x’ angewendet. Dieser Typ von Dyno verfügt über 1024 MB \gls{ram} und kann bis hundertfach horizontal skaliert werden (Scaling out). Der Dyno verfällt nicht in den Schlafmodus, was bedeutet, dass die ersten Anfragen ebenfalls nicht länger dauern als die anschliessenden. 



\section{Open Source Reporting Engine }

% Fragen beantworten wie : Marktanteil, What is claimed, Performance and Community, OpenSource in wie weit? 

% Es soll ein wissenschaftliche Arbeit, darum beschreiben warum diese Methodik genutzt wird, damit es nicht in eine Projektarbeit ausartet.

Als Open Source Reporting Engine werden die Libraries definiert, welche als Einsatzgebiet das Rendern und Generieren von Reports haben. Ein Einsatzgebiet kann das Generieren von Flugtickets, das grafische Aufbereiten von Geschäftszahlen oder einfach nur das Darstellen von Fliesstext sein.

Es gibt im Markt verschiedene dieser OSREs wie Apache PdfBox , iText ,BIRT, Jasper-Reports, um nur einige der Engines zu nennen. Viele dieser OSREs sind auf ein Einsatzgebiet spezialisiert. Meist können diese OSREs nicht nur Reports generieren, sondern diese auch verarbeiten oder verändern \cite[Kap. ~10]{whitington_2012}. Als Zielformat wird oft PDF benutzt. Dieses Format ist ideal, um Druckvorlagen zu erstellen oder die Informationen auf verschiedenen Endgeräten darzustellen. Das macht PDF zum robusten und versatilen Dateiformat. Wir wollen im Folgenden die für die Prototypen genutzen OSREs näher betrachten.


\subsection{JasperReports\textregistered}
Das von Teodor Daciu lancierte Reporting Tool wurde aufgrund grosser Nachfrage im November 2001 in der Version 0.1.5 lanciert \cite[Kap.~1]{heffelfinger_2009}. Die Reporte werden als Vorlagen im XML-Format definiert. Diese Vorlagen können für die Verarbeitung vorkompiliert werden. Der Visual Designer iReport macht es möglich, das Layout grafisch zu bearbeiten. Dank diesem Ansatz kann das Layout vom Programmcode getrennt werden. JasperReports nutzt als Framework iText um einige der Features umzusetzen. 


\subsection{iText}
Als die Studenten- und Kursverwaltung einer Universität fertiggestellt wurde, musste eine geeigenete Druckmöglichkeit gefunden werden. HTML und Word wurden als ungeeignetes Mittel angesehen, und man entschied sich, PDF einzusetzen. Da im Jahr 1998 noch keine geeignete \acrshort{foss} für PDF existierte, wurde eine eigene Library geschrieben, die heute als iText bekannt ist. iText wird heute in verschiedenen Softwares eingesetzt und kann in Tools wie Eclipse/BIRT und JasperReports gefunden werden. NASA nutzt die Library für ihre Blueprints, und Google Calendar gehört ebenfalls zu den Nutzern dieser Library \cite[Kap.~1]{lowagie_2010}.

\subsection{Apache PDFBox}
Im Jahr 2002 wurde für das Projekt Apache Lucene eine Library gesucht, um den Inhalt von PDFs zu extrahieren. Das Ziel war, den Inhalt duch Lucene zu indexieren. Diese Library wurde von Ben Litchfield initialisiert, und seit der ersten Version wurden verschiedene Performance-Verbesserungen eingeführt. Lucene wird von Wikipedia und Twitter genutzt. Zu den Features von Apache PDFBox gehört nicht nur das Extrahieren von Inhalten, sondern auch das Teilen, Vereinen und Füllen von PDFs \cite{apachepdfbox_history}.


\subsection{Gegenüberstellung}

Die hier vorgestellten Open Source Frameworks können mehr als nur PDFs erstellen, obwohl einzig diese die Eigenschaft haben, die in dieser Arbeit geprüft wird. Die meisten dieser Frameworks können Inhalte aus bestehenden PDFs entnehmen, PDFs teilen oder vereinen. 
Wie die Tabelle \ref{table:featuresOSRE} zeigt, sind bei der Ausbaustufe trotzdem Unterschiede festzustellen. 


\begin{table}[h]
\centering

\begin{tabular}{lccc}
               & Apache PDF Box & iText  & JasperReport \\ \hline
PDF-Metadaten           &         X      &   X    &     X        \\
PDF generieren   &         X      &   X    &     X        \\
Bilder einfügen         &  X             &   X    &     X        \\
Formen zeichnen         &  X             &   X    &     X        \\
Tabellen einfügen                &                &   X    &     X        \\
Tabellen-Zellen formatieren      &                &   X    &     X        \\
Layout-Vorlage definieren         &                &        &     X        \\
\end{tabular}
\caption{OSRE PDF-Erstellen Features}
\label{table:featuresOSRE}
\end{table}


\section{ Abgrenzung der Arbeit}

Es ist in dieser Arbeit nicht möglich alle Aspekte von Performance und deren Analyse vorzunehmen. Darum werden die hier erarbeiteten Erkenntnisse nicht als Allgemein gültig definiert. 

\subsection{PDF-Implementation und Layout} 
Die generierten PDFs werden anhand des gleichen Inputs generiert, die Verarbeitung dieser Inputs wird jedoch von jeder Reporting Engine verschieden aufbereitet. Aufgrund des Funktionsumfangs der OSRE kann nicht gewährleistet werden, dass die leistungsstärkste Umsetzung gewählt wurde oder die idealen Features genutzt wurden. Da die ORSE verschiedene Strategien besitzen, wie PDFs erstellt werden, und nicht alle APIs gleich ausgereift sind, sind einige der Layouts nicht vollständig von einer OSRE auf die andere übertragbar. Darum wurde Wert darauf gelegt, dass die Reporte sich schlussendlich ähneln und die Informationen angezeigt werden können.

\subsection{PaaS}
Die verschiedenen Applikationen wurden auf der PaaS Heroku betrieben und getestet. Da die Performance einer Applikation durch verschiedene nicht beinflussbare Ereignisse verändert wird, wie z.B. die Netzwerklatenzzeit oder die Last selbst auf den Providern, ist zu erwarten, dass die Ergebnisse immer unterschiedlich sein werden. 
Ein Aspekt, der in dieser Arbeit nicht betrachtet wird, der jedoch im Zusammenhang mit Performance-Tests auf einer PaaS sehr relevant ist, ist das Load-Balancing. Einerseits werden die User, die die Anfragen stellen, immer die gleiche IP-Adresse besitzen. Auch werden keine Autoscaling-Dynos gestartet, was bedeutet, dass die Anfragen nicht auf mehrere Dynos aufgeteilt, sondern nur auf einem Server verarbeitet werden. Es ist somit klar, dass diese Test-Umgebung mit einer produktiven Umgebung nicht vergleichbar ist und somit die Ergebnisse nicht absolut übertragbar sind.

\end{document}